{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwPL0hIlGKoA"
   },
   "source": [
    "# Sequence to Sequence Implementation #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:24:16.519222Z",
     "iopub.status.busy": "2022-07-02T15:24:16.518262Z",
     "iopub.status.idle": "2022-07-02T15:24:23.854736Z",
     "shell.execute_reply": "2022-07-02T15:24:23.853706Z",
     "shell.execute_reply.started": "2022-07-02T15:24:16.519099Z"
    },
    "executionInfo": {
     "elapsed": 5353,
     "status": "ok",
     "timestamp": 1656166730266,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "t4RZXRUXMsbP"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:24:23.857263Z",
     "iopub.status.busy": "2022-07-02T15:24:23.856590Z",
     "iopub.status.idle": "2022-07-02T15:24:23.865827Z",
     "shell.execute_reply": "2022-07-02T15:24:23.864789Z",
     "shell.execute_reply.started": "2022-07-02T15:24:23.857225Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1656166730266,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "PfGFURQVM4jq"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:24:23.867381Z",
     "iopub.status.busy": "2022-07-02T15:24:23.867001Z",
     "iopub.status.idle": "2022-07-02T15:24:23.885115Z",
     "shell.execute_reply": "2022-07-02T15:24:23.883882Z",
     "shell.execute_reply.started": "2022-07-02T15:24:23.867346Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1656166730267,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "Xz9nLfGxJDKh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:24:23.888194Z",
     "iopub.status.busy": "2022-07-02T15:24:23.887768Z",
     "iopub.status.idle": "2022-07-02T15:24:23.896311Z",
     "shell.execute_reply": "2022-07-02T15:24:23.895181Z",
     "shell.execute_reply.started": "2022-07-02T15:24:23.888156Z"
    },
    "executionInfo": {
     "elapsed": 814,
     "status": "ok",
     "timestamp": 1656166731075,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "fU80Ao-AGaob"
   },
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('/content/ita-eng.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:24:23.898504Z",
     "iopub.status.busy": "2022-07-02T15:24:23.897819Z",
     "iopub.status.idle": "2022-07-02T15:24:31.956256Z",
     "shell.execute_reply": "2022-07-02T15:24:31.955040Z",
     "shell.execute_reply.started": "2022-07-02T15:24:23.898464Z"
    },
    "executionInfo": {
     "elapsed": 7491,
     "status": "ok",
     "timestamp": 1656166738558,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "39RqrnPDMi4x",
    "outputId": "4a42954b-1681-4e07-ca99-4daf8ad327bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-07-02 15:24:24--  https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.18, 2620:100:601f:18::a27d:912\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/ddkmtqz01jc024u/glove.6B.100d.txt [following]\n",
      "--2022-07-02 15:24:24--  https://www.dropbox.com/s/raw/ddkmtqz01jc024u/glove.6B.100d.txt\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc2a2497631126f46f6ed895f5bb.dl.dropboxusercontent.com/cd/0/inline/BoUfTR94AvutO1RuGuX0tHGQ_v1v8M0c0lgDJDXjyRHgKf-ifk414UA52DZnUbQ67C_q2nZDK6QFrwW7DeKG9zWyvaEHSmj4jYgmybs3jYBq4ge7rtHfM0B3xTHxv1e6841tdDfksiwV1dQV5OPctrajZZSQElTsnpjtg6b9JDx7bg/file# [following]\n",
      "--2022-07-02 15:24:25--  https://uc2a2497631126f46f6ed895f5bb.dl.dropboxusercontent.com/cd/0/inline/BoUfTR94AvutO1RuGuX0tHGQ_v1v8M0c0lgDJDXjyRHgKf-ifk414UA52DZnUbQ67C_q2nZDK6QFrwW7DeKG9zWyvaEHSmj4jYgmybs3jYBq4ge7rtHfM0B3xTHxv1e6841tdDfksiwV1dQV5OPctrajZZSQElTsnpjtg6b9JDx7bg/file\n",
      "Resolving uc2a2497631126f46f6ed895f5bb.dl.dropboxusercontent.com (uc2a2497631126f46f6ed895f5bb.dl.dropboxusercontent.com)... 162.125.9.15, 2620:100:601f:15::a27d:90f\n",
      "Connecting to uc2a2497631126f46f6ed895f5bb.dl.dropboxusercontent.com (uc2a2497631126f46f6ed895f5bb.dl.dropboxusercontent.com)|162.125.9.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 347116733 (331M) [text/plain]\n",
      "Saving to: ‘glove.6B.100d.txt’\n",
      "\n",
      "glove.6B.100d.txt   100%[===================>] 331.04M  69.1MB/s    in 5.2s    \n",
      "\n",
      "2022-07-02 15:24:31 (63.2 MB/s) - ‘glove.6B.100d.txt’ saved [347116733/347116733]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmGWTdRmKRph"
   },
   "source": [
    "## Preprocessing Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:24:58.360801Z",
     "iopub.status.busy": "2022-07-02T15:24:58.360290Z",
     "iopub.status.idle": "2022-07-02T15:24:59.597447Z",
     "shell.execute_reply": "2022-07-02T15:24:59.596323Z",
     "shell.execute_reply.started": "2022-07-02T15:24:58.360757Z"
    },
    "executionInfo": {
     "elapsed": 1233,
     "status": "ok",
     "timestamp": 1656166739787,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "9QqElB_nKZos",
    "outputId": "149e3756-e306-4f3d-f98f-f5097647bdf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354238, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>italian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Ciao!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Ciao.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corri!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Corra!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Run!</td>\n",
       "      <td>Correte!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english   italian\n",
       "0     Hi.     Ciao!\n",
       "1     Hi.     Ciao.\n",
       "2    Run!    Corri!\n",
       "3    Run!    Corra!\n",
       "4    Run!  Correte!"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../input/seq2seq/ita.txt', 'r', encoding=\"utf8\") as f:\n",
    "    eng=[]\n",
    "    ita=[]\n",
    "    for i in f.readlines():\n",
    "        eng.append(i.split(\"\\t\")[0])\n",
    "        ita.append(i.split(\"\\t\")[1])\n",
    "data = pd.DataFrame(data=list(zip(eng, ita)), columns=['english','italian'])\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:24:59.601009Z",
     "iopub.status.busy": "2022-07-02T15:24:59.599825Z",
     "iopub.status.idle": "2022-07-02T15:25:19.041239Z",
     "shell.execute_reply": "2022-07-02T15:25:19.040126Z",
     "shell.execute_reply.started": "2022-07-02T15:24:59.600966Z"
    },
    "executionInfo": {
     "elapsed": 26845,
     "status": "ok",
     "timestamp": 1656166766627,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "J0L4JNftNPF2",
    "outputId": "e9af88cf-f05c-4884-cf83-c9c21b29ef1a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>italian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi</td>\n",
       "      <td>ciao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi</td>\n",
       "      <td>ciao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run</td>\n",
       "      <td>corri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>run</td>\n",
       "      <td>corra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>run</td>\n",
       "      <td>correte</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english  italian\n",
       "0      hi     ciao\n",
       "1      hi     ciao\n",
       "2     run    corri\n",
       "3     run    corra\n",
       "4     run  correte"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decontractions(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "\n",
    "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
    "\n",
    "    return phrase\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = decontractions(text)\n",
    "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
    "    return text\n",
    "\n",
    "def preprocess_ita(text):\n",
    "    text = text.lower()\n",
    "    text = decontractions(text)\n",
    "    text = re.sub('[$)\\?\"’.°!;\\'€%:,(/]', '', text)\n",
    "    text = re.sub('\\u200b', ' ', text)\n",
    "    text = re.sub('\\xa0', ' ', text)\n",
    "    text = re.sub('-', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "data['english'] = data['english'].apply(preprocess)\n",
    "data['italian'] = data['italian'].apply(preprocess_ita)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:25:19.043900Z",
     "iopub.status.busy": "2022-07-02T15:25:19.043519Z",
     "iopub.status.idle": "2022-07-02T15:25:21.838388Z",
     "shell.execute_reply": "2022-07-02T15:25:21.837383Z",
     "shell.execute_reply.started": "2022-07-02T15:25:19.043864Z"
    },
    "executionInfo": {
     "elapsed": 2051,
     "status": "ok",
     "timestamp": 1656166768674,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "8Lqosh95ONsX",
    "outputId": "625b6592-3b8d-4262-fbef-4cf3e13ddf4b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>italian</th>\n",
       "      <th>english_inp</th>\n",
       "      <th>english_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start&gt; ciao &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; hi</td>\n",
       "      <td>hi &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start&gt; ciao &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; hi</td>\n",
       "      <td>hi &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start&gt; corri &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; run</td>\n",
       "      <td>run &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start&gt; corra &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; run</td>\n",
       "      <td>run &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start&gt; correte &lt;end&gt;</td>\n",
       "      <td>&lt;start&gt; run</td>\n",
       "      <td>run &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 italian  english_inp english_out\n",
       "0     <start> ciao <end>   <start> hi    hi <end>\n",
       "1     <start> ciao <end>   <start> hi    hi <end>\n",
       "2    <start> corri <end>  <start> run   run <end>\n",
       "3    <start> corra <end>  <start> run   run <end>\n",
       "4  <start> correte <end>  <start> run   run <end>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data['italian_len'] = data['italian'].str.split().apply(len)\n",
    "data = data[data['italian_len'] < 20]\n",
    "\n",
    "data['english_len'] = data['english'].str.split().apply(len)\n",
    "data = data[data['english_len'] < 20]\n",
    "\n",
    "data['italian'] = '<start> ' + data['italian'] +' <end>'\n",
    "data['english_inp'] = '<start> ' + data['english'].astype(str)\n",
    "data['english_out'] = data['english'].astype(str) + ' <end>'\n",
    "\n",
    "data = data.drop(['english','italian_len','english_len'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nX-95UgsN8XB"
   },
   "source": [
    "### Data Pipeline ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:25:21.840565Z",
     "iopub.status.busy": "2022-07-02T15:25:21.839737Z",
     "iopub.status.idle": "2022-07-02T15:25:22.247252Z",
     "shell.execute_reply": "2022-07-02T15:25:22.246197Z",
     "shell.execute_reply.started": "2022-07-02T15:25:21.840527Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1656166768674,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "8mqEyc4ZN8XB"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, validation = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:25:22.250999Z",
     "iopub.status.busy": "2022-07-02T15:25:22.250170Z",
     "iopub.status.idle": "2022-07-02T15:25:22.256957Z",
     "shell.execute_reply": "2022-07-02T15:25:22.255901Z",
     "shell.execute_reply.started": "2022-07-02T15:25:22.250958Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1656166768675,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "bibPPnbzN8XC"
   },
   "outputs": [],
   "source": [
    "# Only for the first sentance, adding a token <end> so that we will have <end> in tokenizer\n",
    "\n",
    "train.iloc[0]['english_inp']= str(train.iloc[0]['english_inp']) + ' <end>'\n",
    "train.iloc[0]['english_out']= str(train.iloc[0]['english_out']) + ' <end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:25:22.259208Z",
     "iopub.status.busy": "2022-07-02T15:25:22.258564Z",
     "iopub.status.idle": "2022-07-02T15:25:22.345702Z",
     "shell.execute_reply": "2022-07-02T15:25:22.344596Z",
     "shell.execute_reply.started": "2022-07-02T15:25:22.259166Z"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1656166768676,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "h2lXhI4qs6c3"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../input/tknizer/tknizer_eng.pickle', 'rb') as handle:\n",
    "    tknizer_eng = pickle.load(handle)\n",
    "with open('../input/tknizer/tknizer_ita.pickle', 'rb') as handle:\n",
    "    tknizer_ita = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:25:22.347737Z",
     "iopub.status.busy": "2022-07-02T15:25:22.347307Z",
     "iopub.status.idle": "2022-07-02T15:25:22.355486Z",
     "shell.execute_reply": "2022-07-02T15:25:22.354574Z",
     "shell.execute_reply.started": "2022-07-02T15:25:22.347698Z"
    },
    "executionInfo": {
     "elapsed": 6769,
     "status": "ok",
     "timestamp": 1656166775437,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "-_TAJB2Psxc_"
   },
   "outputs": [],
   "source": [
    "# tknizer_ita = Tokenizer()\n",
    "# tknizer_ita.fit_on_texts(train['italian'].values)\n",
    "\n",
    "# tknizer_eng = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "# tknizer_eng.fit_on_texts(train['english_inp'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:25:22.359327Z",
     "iopub.status.busy": "2022-07-02T15:25:22.357845Z",
     "iopub.status.idle": "2022-07-02T15:25:22.365071Z",
     "shell.execute_reply": "2022-07-02T15:25:22.364134Z",
     "shell.execute_reply.started": "2022-07-02T15:25:22.359284Z"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1656166775438,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "pIBuRnvgtN9V"
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('tknizer_eng.pickle', 'wb') as handle:\n",
    "#     pickle.dump(tknizer_eng, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open('tknizer_ita.pickle', 'wb') as handle:\n",
    "#     pickle.dump(tknizer_ita, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:25:22.367877Z",
     "iopub.status.busy": "2022-07-02T15:25:22.366552Z",
     "iopub.status.idle": "2022-07-02T15:25:22.376728Z",
     "shell.execute_reply": "2022-07-02T15:25:22.375563Z",
     "shell.execute_reply.started": "2022-07-02T15:25:22.367836Z"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1656166775438,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "8V-o2eT7N8XD",
    "outputId": "000fcb37-17b3-4413-e669-5ba09de06d06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13043\n",
      "26625\n"
     ]
    }
   ],
   "source": [
    "vocab_size_eng=len(tknizer_eng.word_index.keys())\n",
    "print(vocab_size_eng)\n",
    "vocab_size_ita=len(tknizer_ita.word_index.keys())\n",
    "print(vocab_size_ita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:25:22.379625Z",
     "iopub.status.busy": "2022-07-02T15:25:22.378386Z",
     "iopub.status.idle": "2022-07-02T15:25:22.387495Z",
     "shell.execute_reply": "2022-07-02T15:25:22.386345Z",
     "shell.execute_reply.started": "2022-07-02T15:25:22.379577Z"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1656166775439,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "K3L265A6N8XD",
    "outputId": "03763f59-be6d-47ad-d27f-b5e1d233a705"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10347)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknizer_eng.word_index['<start>'], tknizer_eng.word_index['<end>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:25:22.392381Z",
     "iopub.status.busy": "2022-07-02T15:25:22.391343Z",
     "iopub.status.idle": "2022-07-02T15:25:33.696107Z",
     "shell.execute_reply": "2022-07-02T15:25:33.695029Z",
     "shell.execute_reply.started": "2022-07-02T15:25:22.392339Z"
    },
    "executionInfo": {
     "elapsed": 8104,
     "status": "ok",
     "timestamp": 1656166783524,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "A81-hfz0N8XE"
   },
   "outputs": [],
   "source": [
    "embeddings_index = dict()\n",
    "f = open('glove.6B.100d.txt', encoding='utf8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size_eng+1, 100))\n",
    "for word, i in tknizer_eng.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:25:33.698610Z",
     "iopub.status.busy": "2022-07-02T15:25:33.697801Z",
     "iopub.status.idle": "2022-07-02T15:25:33.715297Z",
     "shell.execute_reply": "2022-07-02T15:25:33.714180Z",
     "shell.execute_reply.started": "2022-07-02T15:25:33.698572Z"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1656166783525,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "PpG3IzenN8XF"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data, tknizer_ita, tknizer_eng, max_len):\n",
    "        self.encoder_inps = data['italian'].values\n",
    "        self.decoder_inps = data['english_inp'].values\n",
    "        self.decoder_outs = data['english_out'].values\n",
    "        self.tknizer_eng = tknizer_eng\n",
    "        self.tknizer_ita = tknizer_ita\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
    "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.decoder_inps[i]])\n",
    "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.decoder_outs[i]])\n",
    "\n",
    "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
    "        \n",
    "\n",
    "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoder_inps)\n",
    "\n",
    "    \n",
    "class Dataloader(tf.keras.utils.Sequence):    \n",
    "    def __init__(self, dataset, batch_size=1):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "\n",
    "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
    "        return tuple([[batch[0],batch[1]],batch[2]]) #([italian, english_inp], english_out)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indexes) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:25:33.717637Z",
     "iopub.status.busy": "2022-07-02T15:25:33.717214Z",
     "iopub.status.idle": "2022-07-02T15:25:33.733969Z",
     "shell.execute_reply": "2022-07-02T15:25:33.732914Z",
     "shell.execute_reply.started": "2022-07-02T15:25:33.717598Z"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1656166783526,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "gmIIL3wBN8XF"
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train, tknizer_ita, tknizer_eng, 20)\n",
    "test_dataset  = Dataset(validation, tknizer_ita, tknizer_eng, 20)\n",
    "\n",
    "train_dataloader = Dataloader(train_dataset, batch_size=1024)\n",
    "test_dataloader = Dataloader(test_dataset, batch_size=1024)\n",
    "\n",
    "# print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyfZo8fmLOec"
   },
   "source": [
    "## Simple Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:26:06.602687Z",
     "iopub.status.busy": "2022-07-02T15:26:06.602184Z",
     "iopub.status.idle": "2022-07-02T15:26:06.620976Z",
     "shell.execute_reply": "2022-07-02T15:26:06.619949Z",
     "shell.execute_reply.started": "2022-07-02T15:26:06.602643Z"
    },
    "id": "9cex2XfCLOew"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
    "        super().__init__()\n",
    "        self.inp_vocab_size = inp_vocab_size\n",
    "        self.enc_embedding_size = embedding_size\n",
    "        self.enc_lstm_size = lstm_size\n",
    "        self.enc_input_length = input_length\n",
    "        \n",
    "        self.encoder_embedding = Embedding(input_dim=self.inp_vocab_size, output_dim=self.enc_embedding_size, \n",
    "                                           input_length=self.enc_input_length, mask_zero=True, name=\"Embedding_Layer_Encoder\")\n",
    "        self.encoder_lstm = LSTM(self.enc_lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
    "\n",
    "    def call(self,input_sequence,states):\n",
    "        \n",
    "        self.input_embedd = self.encoder_embedding(input_sequence)\n",
    "        self.encoder_output, self.lstm_state_h,self.lstm_state_c = self.encoder_lstm(self.input_embedd, initial_state = states)\n",
    "        return self.encoder_output, self.lstm_state_h,self.lstm_state_c #encoder_output, last time step's hidden and cell state\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.initial_hidden_state = tf.random.normal(shape=(self.batch_size,self.enc_lstm_size))\n",
    "        self.initial_cell_state = tf.random.normal(shape=(self.batch_size,self.enc_lstm_size))\n",
    "        return [self.initial_hidden_state,self.initial_cell_state]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:26:12.629077Z",
     "iopub.status.busy": "2022-07-02T15:26:12.626410Z",
     "iopub.status.idle": "2022-07-02T15:26:12.645095Z",
     "shell.execute_reply": "2022-07-02T15:26:12.643774Z",
     "shell.execute_reply.started": "2022-07-02T15:26:12.629033Z"
    },
    "id": "x1ES1-sJLOe4"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length, flag=0):\n",
    "\n",
    "        super().__init__()\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.dec_embedding_size = embedding_size\n",
    "        self.dec_lstm_size = lstm_size\n",
    "        self.dec_input_length = input_length\n",
    "        self.flag = flag\n",
    "        \n",
    "        if self.flag == 0:\n",
    "            self.decoder_embedding = Embedding(input_dim=self.out_vocab_size, output_dim=self.dec_embedding_size, \n",
    "                                           input_length=self.dec_input_length, mask_zero=True, name=\"Embedding_Layer_Decoder\")\n",
    "        else:\n",
    "            self.decoder_embedding = Embedding(input_dim=self.out_vocab_size, output_dim=self.dec_embedding_size, \n",
    "                                           input_length=self.dec_input_length, mask_zero=True, weights=[embedding_matrix], trainable=False, name=\"Embedding_Layer_Decoder\")\n",
    "            \n",
    "            \n",
    "        self.decoder_lstm = LSTM(self.dec_lstm_size, return_state=True, return_sequences=True, name=\"Decoder_LSTM\")\n",
    "        \n",
    "\n",
    "\n",
    "    def call(self,input_sequence,initial_state):\n",
    "        \n",
    "        self.input_embedd = self.decoder_embedding(input_sequence)\n",
    "        decoder_output, decoder_state_h, decoder_state_c = self.decoder_lstm(self.input_embedd, initial_state=initial_state)\n",
    "        return decoder_output, decoder_state_h, decoder_state_c\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T18:16:29.100561Z",
     "iopub.status.busy": "2022-06-19T18:16:29.099756Z",
     "iopub.status.idle": "2022-06-19T18:16:29.111939Z",
     "shell.execute_reply": "2022-06-19T18:16:29.110904Z",
     "shell.execute_reply.started": "2022-06-19T18:16:29.100525Z"
    },
    "id": "slJpDxOvN8XJ"
   },
   "outputs": [],
   "source": [
    "class Encoder_Decoder(tf.keras.Model):\n",
    "    def __init__(self, encoder_inputs_length,decoder_inputs_length, output_vocab_size,batch_size):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.encoder = Encoder(inp_vocab_size=vocab_size_ita+1, embedding_size=50, lstm_size=64, input_length=encoder_inputs_length)\n",
    "        self.decoder = Decoder(out_vocab_size=vocab_size_eng+1, embedding_size=100, lstm_size=64, input_length=decoder_inputs_length, flag = 1)\n",
    "        self.dense   = Dense(output_vocab_size, activation='softmax')\n",
    "        \n",
    "        \n",
    "    def call(self, data):\n",
    "        input_seq,output_seq = data[0], data[1] \n",
    "        \n",
    "        # Encoder\n",
    "        initial_state=self.encoder.initialize_states(self.batch_size)\n",
    "        encoder_output, encoder_final_h, encoder_final_c = self.encoder(input_seq,initial_state)\n",
    "        dec_state = [encoder_final_h,encoder_final_c]\n",
    "\n",
    "        #Decoder\n",
    "        dec_input = output_seq[:,0] # First word <start>\n",
    "        dec_input = dec_input[:,np.newaxis]\n",
    "        decoder_output,dec_h,dec_c = self.decoder(dec_input, dec_state)\n",
    "        dec_state = [dec_h,dec_c] # Decoder state that'll be passed on next timestep\n",
    "\n",
    "        for timestep in range(1,20):\n",
    "     \n",
    "          dec_input = output_seq[:,timestep] # decoder input at timestep\n",
    "          dec_input = dec_input[:,np.newaxis]\n",
    "          temp,dec_h,dec_c = self.decoder(dec_input, dec_state) # hidden and cell state from previous timestep\n",
    "          dec_state = [dec_h,dec_c] # passing on current hidden and cell state to next timestep\n",
    "\n",
    "          decoder_output = tf.keras.layers.Concatenate(axis=1)([decoder_output, temp])\n",
    "          # print(timestep, decoder_output.shape)\n",
    "\n",
    "        dropout = tf.keras.layers.Dropout(0.15)(decoder_output)\n",
    "        output = self.dense(decoder_output)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T18:17:21.979929Z",
     "iopub.status.busy": "2022-06-19T18:17:21.979588Z",
     "iopub.status.idle": "2022-06-19T18:43:30.406139Z",
     "shell.execute_reply": "2022-06-19T18:43:30.404833Z",
     "shell.execute_reply.started": "2022-06-19T18:17:21.979900Z"
    },
    "executionInfo": {
     "elapsed": 1804641,
     "status": "ok",
     "timestamp": 1655639878334,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "ts-2ZtYzAd2V",
    "outputId": "b92f560d-5c18-472c-ef9d-eee346b274f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 18:17:22.956353: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n",
      "2022-06-19 18:17:23.383984: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "276/276 [==============================] - 125s 283ms/step - loss: 2.0312 - val_loss: 1.8413\n",
      "Epoch 2/25\n",
      "276/276 [==============================] - 59s 215ms/step - loss: 1.8065 - val_loss: 1.7566\n",
      "Epoch 3/25\n",
      "276/276 [==============================] - 60s 216ms/step - loss: 1.7078 - val_loss: 1.6443\n",
      "Epoch 4/25\n",
      "276/276 [==============================] - 60s 217ms/step - loss: 1.5675 - val_loss: 1.4853\n",
      "Epoch 5/25\n",
      "276/276 [==============================] - 61s 221ms/step - loss: 1.4109 - val_loss: 1.3392\n",
      "Epoch 6/25\n",
      "276/276 [==============================] - 59s 213ms/step - loss: 1.2835 - val_loss: 1.2322\n",
      "Epoch 7/25\n",
      "276/276 [==============================] - 60s 216ms/step - loss: 1.1843 - val_loss: 1.1452\n",
      "Epoch 8/25\n",
      "276/276 [==============================] - 60s 218ms/step - loss: 1.0989 - val_loss: 1.0676\n",
      "Epoch 9/25\n",
      "276/276 [==============================] - 60s 216ms/step - loss: 1.0227 - val_loss: 0.9990\n",
      "Epoch 10/25\n",
      "276/276 [==============================] - 61s 221ms/step - loss: 0.9548 - val_loss: 0.9392\n",
      "Epoch 11/25\n",
      "276/276 [==============================] - 60s 218ms/step - loss: 0.8959 - val_loss: 0.8877\n",
      "Epoch 12/25\n",
      "276/276 [==============================] - 60s 219ms/step - loss: 0.8446 - val_loss: 0.8443\n",
      "Epoch 13/25\n",
      "276/276 [==============================] - 62s 223ms/step - loss: 0.7991 - val_loss: 0.8050\n",
      "Epoch 14/25\n",
      "276/276 [==============================] - 60s 217ms/step - loss: 0.7581 - val_loss: 0.7692\n",
      "Epoch 15/25\n",
      "276/276 [==============================] - 60s 217ms/step - loss: 0.7209 - val_loss: 0.7385\n",
      "Epoch 16/25\n",
      "276/276 [==============================] - 60s 218ms/step - loss: 0.6872 - val_loss: 0.7096\n",
      "Epoch 17/25\n",
      "276/276 [==============================] - 60s 217ms/step - loss: 0.6566 - val_loss: 0.6834\n",
      "Epoch 18/25\n",
      "276/276 [==============================] - 60s 217ms/step - loss: 0.6291 - val_loss: 0.6597\n",
      "Epoch 19/25\n",
      "276/276 [==============================] - 60s 217ms/step - loss: 0.6037 - val_loss: 0.6394\n",
      "Epoch 20/25\n",
      "276/276 [==============================] - 61s 219ms/step - loss: 0.5807 - val_loss: 0.6202\n",
      "Epoch 21/25\n",
      "276/276 [==============================] - 59s 213ms/step - loss: 0.5594 - val_loss: 0.6023\n",
      "Epoch 22/25\n",
      "276/276 [==============================] - 60s 218ms/step - loss: 0.5398 - val_loss: 0.5875\n",
      "Epoch 23/25\n",
      "276/276 [==============================] - 59s 215ms/step - loss: 0.5220 - val_loss: 0.5733\n",
      "Epoch 24/25\n",
      "276/276 [==============================] - 60s 217ms/step - loss: 0.5052 - val_loss: 0.5590\n",
      "Epoch 25/25\n",
      "276/276 [==============================] - 60s 216ms/step - loss: 0.4896 - val_loss: 0.5465\n",
      "Model: \"encoder__decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_2 (Encoder)          multiple                  1364240   \n",
      "_________________________________________________________________\n",
      "decoder_1 (Decoder)          multiple                  1350640   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  850395    \n",
      "=================================================================\n",
      "Total params: 3,565,275\n",
      "Trainable params: 2,256,875\n",
      "Non-trainable params: 1,308,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model  = Encoder_Decoder(encoder_inputs_length=20,decoder_inputs_length=1,output_vocab_size=vocab_size_eng, batch_size = 1024)\n",
    "opt = tf.keras.optimizers.Adam(0.001)\n",
    "model.compile(optimizer=opt,loss=tf.keras.losses.SparseCategoricalCrossentropy())\n",
    "\n",
    "train_steps=train.shape[0]//1024\n",
    "valid_steps=validation.shape[0]//1024\n",
    "\n",
    "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=25, validation_data=test_dataloader, validation_steps=valid_steps)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T18:46:58.631091Z",
     "iopub.status.busy": "2022-06-19T18:46:58.630705Z",
     "iopub.status.idle": "2022-06-19T19:11:58.363643Z",
     "shell.execute_reply": "2022-06-19T19:11:58.362846Z",
     "shell.execute_reply.started": "2022-06-19T18:46:58.631060Z"
    },
    "executionInfo": {
     "elapsed": 1739380,
     "status": "ok",
     "timestamp": 1655641633138,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "LFS0_Q0D0q1Y",
    "outputId": "14bd1c36-5936-4caa-861a-3326d034e81b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "276/276 [==============================] - 60s 218ms/step - loss: 0.4751 - val_loss: 0.5353\n",
      "Epoch 2/25\n",
      "276/276 [==============================] - 61s 220ms/step - loss: 0.4615 - val_loss: 0.5243\n",
      "Epoch 3/25\n",
      "276/276 [==============================] - 59s 215ms/step - loss: 0.4485 - val_loss: 0.5146\n",
      "Epoch 4/25\n",
      "276/276 [==============================] - 60s 217ms/step - loss: 0.4365 - val_loss: 0.5054\n",
      "Epoch 5/25\n",
      "276/276 [==============================] - 62s 223ms/step - loss: 0.4249 - val_loss: 0.4969\n",
      "Epoch 6/25\n",
      "276/276 [==============================] - 60s 218ms/step - loss: 0.4143 - val_loss: 0.4884\n",
      "Epoch 7/25\n",
      "276/276 [==============================] - 60s 218ms/step - loss: 0.4037 - val_loss: 0.4798\n",
      "Epoch 8/25\n",
      "276/276 [==============================] - 60s 218ms/step - loss: 0.3937 - val_loss: 0.4724\n",
      "Epoch 9/25\n",
      "276/276 [==============================] - 59s 213ms/step - loss: 0.3844 - val_loss: 0.4649\n",
      "Epoch 10/25\n",
      "276/276 [==============================] - 60s 217ms/step - loss: 0.3754 - val_loss: 0.4584\n",
      "Epoch 11/25\n",
      "276/276 [==============================] - 59s 215ms/step - loss: 0.3672 - val_loss: 0.4524\n",
      "Epoch 12/25\n",
      "276/276 [==============================] - 60s 219ms/step - loss: 0.3591 - val_loss: 0.4467\n",
      "Epoch 13/25\n",
      "276/276 [==============================] - 61s 222ms/step - loss: 0.3515 - val_loss: 0.4412\n",
      "Epoch 14/25\n",
      "276/276 [==============================] - 60s 216ms/step - loss: 0.3443 - val_loss: 0.4362\n",
      "Epoch 15/25\n",
      "276/276 [==============================] - 61s 219ms/step - loss: 0.3377 - val_loss: 0.4315\n",
      "Epoch 16/25\n",
      "276/276 [==============================] - 59s 213ms/step - loss: 0.3311 - val_loss: 0.4270\n",
      "Epoch 17/25\n",
      "276/276 [==============================] - 58s 212ms/step - loss: 0.3249 - val_loss: 0.4227\n",
      "Epoch 18/25\n",
      "276/276 [==============================] - 59s 213ms/step - loss: 0.3193 - val_loss: 0.4186\n",
      "Epoch 19/25\n",
      "276/276 [==============================] - 59s 213ms/step - loss: 0.3137 - val_loss: 0.4146\n",
      "Epoch 20/25\n",
      "276/276 [==============================] - 59s 214ms/step - loss: 0.3085 - val_loss: 0.4120\n",
      "Epoch 21/25\n",
      "276/276 [==============================] - 60s 216ms/step - loss: 0.3037 - val_loss: 0.4085\n",
      "Epoch 22/25\n",
      "276/276 [==============================] - 61s 219ms/step - loss: 0.2988 - val_loss: 0.4054\n",
      "Epoch 23/25\n",
      "276/276 [==============================] - 60s 218ms/step - loss: 0.2941 - val_loss: 0.4020\n",
      "Epoch 24/25\n",
      "276/276 [==============================] - 62s 226ms/step - loss: 0.2897 - val_loss: 0.3992\n",
      "Epoch 25/25\n",
      "276/276 [==============================] - 59s 215ms/step - loss: 0.2854 - val_loss: 0.3971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f38340b4610>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=25, validation_data=test_dataloader, validation_steps=valid_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LOEAU5RGo2J"
   },
   "outputs": [],
   "source": [
    "model.save_weights('model_50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T20:04:34.687017Z",
     "iopub.status.busy": "2022-06-19T20:04:34.686379Z",
     "iopub.status.idle": "2022-06-19T20:04:34.696014Z",
     "shell.execute_reply": "2022-06-19T20:04:34.694924Z",
     "shell.execute_reply.started": "2022-06-19T20:04:34.686965Z"
    },
    "executionInfo": {
     "elapsed": 414,
     "status": "ok",
     "timestamp": 1655657540501,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "SkARSlZgLOfE"
   },
   "outputs": [],
   "source": [
    "def predict(input_data):\n",
    "    \n",
    "  initial_state = [tf.random.normal((1,64)),tf.random.normal((1,64))] # Initial state of Encoder\n",
    "\n",
    "  enc_output, state_h, state_c = model.layers[0](input_data,initial_state) #Encoder\n",
    "\n",
    "  dec_input = np.array(tknizer_eng.texts_to_sequences(['<start>'])) # First word\n",
    "\n",
    "  translated_seq = []\n",
    "\n",
    "  final_word = ''\n",
    "\n",
    "  i=0\n",
    "  while ((i<20) or (final_word == '<end>')):\n",
    "    dec_output,state_h,state_c = model.layers[1](dec_input,[state_h,state_c]) # Decoder\n",
    "    pred_output = model.layers[2](dec_output) # Dense\n",
    "    \n",
    "    max_prob_word_index = tf.math.argmax(pred_output[0][0], axis=0)\n",
    "\n",
    "    final_word = list(tknizer_eng.word_index.keys())[max_prob_word_index]\n",
    "    translated_seq.append(final_word)\n",
    "\n",
    "    dec_input = np.array(tknizer_eng.texts_to_sequences([final_word])) # Predicted word passed on to next timestep\n",
    "    i += 1\n",
    "\n",
    "  translated_seq = ' '.join(translated_seq)\n",
    "  return translated_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T20:12:59.153163Z",
     "iopub.status.busy": "2022-06-19T20:12:59.152787Z",
     "iopub.status.idle": "2022-06-19T20:12:59.168007Z",
     "shell.execute_reply": "2022-06-19T20:12:59.167221Z",
     "shell.execute_reply.started": "2022-06-19T20:12:59.153133Z"
    },
    "executionInfo": {
     "elapsed": 1334,
     "status": "ok",
     "timestamp": 1655657549409,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "GL9t1nd62J6D"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "val_index = [index for index in validation.index.values]\n",
    "random_seq_index = random.sample(val_index,1000)\n",
    "\n",
    "sample_ita = data.loc[random_seq_index,'italian']\n",
    "actual_sample_eng = data.loc[random_seq_index,'english_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T20:13:03.712867Z",
     "iopub.status.busy": "2022-06-19T20:13:03.712511Z",
     "iopub.status.idle": "2022-06-19T20:13:03.737272Z",
     "shell.execute_reply": "2022-06-19T20:13:03.736386Z",
     "shell.execute_reply.started": "2022-06-19T20:13:03.712838Z"
    }
   },
   "outputs": [],
   "source": [
    "test_seq = tknizer_ita.texts_to_sequences(sample_ita)\n",
    "padded_test_seq = pad_sequences(test_seq, 20, dtype='int32', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T20:17:58.377171Z",
     "iopub.status.busy": "2022-06-19T20:17:58.376347Z",
     "iopub.status.idle": "2022-06-19T20:20:19.725105Z",
     "shell.execute_reply": "2022-06-19T20:20:19.724275Z",
     "shell.execute_reply.started": "2022-06-19T20:17:58.377136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Bleu: 0.7634903560832931\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "pred_eng = []\n",
    "for seq,actual in zip(padded_test_seq,actual_sample_eng):\n",
    "    pred = predict(seq[np.newaxis,:])\n",
    "    pred_eng.append(pred)\n",
    "pred_eng = pd.Series(pred_eng)\n",
    "print('Corpus Bleu:',nltk.translate.bleu_score.corpus_bleu(pred_eng,actual_sample_eng))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PU4KIsGxLOfK"
   },
   "source": [
    "## Encoder Decoder with Attention Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMm3ADQDLOfK"
   },
   "source": [
    "### Encoder ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:26:21.570996Z",
     "iopub.status.busy": "2022-07-02T15:26:21.567111Z",
     "iopub.status.idle": "2022-07-02T15:26:21.587779Z",
     "shell.execute_reply": "2022-07-02T15:26:21.586761Z",
     "shell.execute_reply.started": "2022-07-02T15:26:21.570949Z"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1656166783527,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "id4zqS_jJDKz"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
    "        super().__init__()\n",
    "        self.inp_vocab_size = inp_vocab_size\n",
    "        self.enc_embedding_size = embedding_size\n",
    "        self.enc_lstm_size = lstm_size\n",
    "        self.enc_input_length = input_length\n",
    "        \n",
    "        self.encoder_embedding = Embedding(input_dim=self.inp_vocab_size, output_dim=self.enc_embedding_size, \n",
    "                                           input_length=self.enc_input_length, mask_zero=True, name=\"Embedding_Layer_Encoder\")\n",
    "        self.encoder_lstm = LSTM(self.enc_lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
    "\n",
    "    def call(self,input_sequence,states):\n",
    "        \n",
    "        self.input_embedd = self.encoder_embedding(input_sequence)\n",
    "        self.encoder_output, self.lstm_state_h,self.lstm_state_c = self.encoder_lstm(self.input_embedd, initial_state = states)\n",
    "        return self.encoder_output, self.lstm_state_h,self.lstm_state_c #encoder_output, last time step's hidden and cell state\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.initial_hidden_state = tf.random.normal((self.batch_size,self.enc_lstm_size))\n",
    "        self.initial_cell_state = tf.random.normal((self.batch_size,self.enc_lstm_size))\n",
    "        return [self.initial_hidden_state,self.initial_cell_state]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXn278lhLYRM"
   },
   "source": [
    "### Attention ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:26:23.585322Z",
     "iopub.status.busy": "2022-07-02T15:26:23.584521Z",
     "iopub.status.idle": "2022-07-02T15:26:23.604372Z",
     "shell.execute_reply": "2022-07-02T15:26:23.602971Z",
     "shell.execute_reply.started": "2022-07-02T15:26:23.585276Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1656166785052,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "B3JJNOg4JDK0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.eager import context\n",
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self,scoring_fun, att_units, k = 4):\n",
    "        super().__init__()\n",
    "        self.scoring_fun = scoring_fun\n",
    "        self.att_units = att_units\n",
    "\n",
    "        if self.scoring_fun=='dot':\n",
    "            pass\n",
    "        elif self.scoring_fun == 'general':\n",
    "            pass\n",
    "        elif self.scoring_fun == 'concat':\n",
    "            self.k = k\n",
    "        \n",
    "    def call(self,decoder_hidden_state_batch,encoder_outputs_batch):\n",
    "\n",
    "        if self.scoring_fun == 'dot':\n",
    "            scores = tf.keras.layers.Dot(axes=(2,1))([encoder_outputs_batch,decoder_hidden_state_batch[:,:,np.newaxis]])\n",
    "            softmax_scores = np.exp(scores) / np.sum(np.exp(scores), axis=0)\n",
    "            softmax_scores = np.squeeze(softmax_scores, axis=2)\n",
    "\n",
    "                \n",
    "        elif self.scoring_fun == 'general':\n",
    "            \n",
    "            weights = np.random.rand(encoder_outputs_batch.shape[2], decoder_hidden_state_batch.shape[1])\n",
    "            temp1 = np.tensordot(encoder_outputs_batch,weights, axes=((2),(0))) # 1024x20x64\n",
    "            temp2 = np.tensordot(decoder_hidden_state_batch,weights, axes=((1),(1))) # 1024x64\n",
    "            scores = tf.keras.layers.Dot(axes=(2,1))([temp1,temp2[:,:,np.newaxis]]) # 1024x20x1\n",
    "            \n",
    "            scores = np.squeeze(scores,axis=2)\n",
    "            temp_scores = scores/tf.norm(scores)\n",
    "            softmax_scores = np.exp(temp_scores) / np.sum(np.exp(temp_scores), axis=0) \n",
    "            \n",
    "        elif self.scoring_fun == 'concat':\n",
    "            \n",
    "            weights_enc = np.random.rand(encoder_outputs_batch.shape[2],self.k)\n",
    "            weights_dec = np.random.rand(decoder_hidden_state_batch.shape[1],self.k)\n",
    "            v = np.random.rand(self.k,1)\n",
    "            \n",
    "            temp_enc = np.tensordot(encoder_outputs_batch,weights_enc, axes=((2),(0))) # 1024x20xk\n",
    "            \n",
    "            temp_dec = np.tensordot(decoder_hidden_state_batch,weights_dec, axes=((1),(0))) # 1024xk\n",
    "            temp_dec = temp_dec[:,np.newaxis,:] #1024x1xk\n",
    "            temp_dec = np.repeat(temp_dec,encoder_outputs_batch.shape[1],axis=1) #1024x20xk\n",
    "            \n",
    "            temp = np.add(temp_enc,temp_dec) #1024x20xk\n",
    "            temp = np.tanh(temp) #1024x20xk\n",
    "            \n",
    "            scores = np.tensordot(temp,v, axes=((2),(0))) #1024x20x1\n",
    "            softmax_scores = np.exp(scores) / np.sum(np.exp(scores), axis=0) #1024x20x1\n",
    "            softmax_scores = np.squeeze(softmax_scores, axis=2) #1024x20\n",
    "\n",
    "        context_vector = tf.keras.layers.Dot(axes=(1,1))([encoder_outputs_batch,softmax_scores])\n",
    "        \n",
    "        return context_vector,softmax_scores[:,:,np.newaxis] #BatchSizexAtt_Units, BatchSizexTimestepsx1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FHrurjUMGAi"
   },
   "source": [
    "### Decoder ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OneStepDecoder ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:26:28.467637Z",
     "iopub.status.busy": "2022-07-02T15:26:28.466653Z",
     "iopub.status.idle": "2022-07-02T15:26:28.481150Z",
     "shell.execute_reply": "2022-07-02T15:26:28.479763Z",
     "shell.execute_reply.started": "2022-07-02T15:26:28.467591Z"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1656166785053,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "Kc8m7lmOL097"
   },
   "outputs": [],
   "source": [
    "class OneStepDecoder(tf.keras.layers.Layer):\n",
    "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units,flag=0):\n",
    "    \n",
    "    # Initializing decoder embedding layer, LSTM and other objects.\n",
    "    \n",
    "    super().__init__()\n",
    "    self.tar_vocab_size = tar_vocab_size\n",
    "    self.embedding_dim = embedding_dim\n",
    "    self.input_length = input_length\n",
    "    self.dec_units = dec_units\n",
    "    self.score_fun = score_fun\n",
    "    self.att_units = att_units\n",
    "    self.flag = flag\n",
    "    \n",
    "    if self.flag == 0:\n",
    "        self.decoder_embedding = Embedding(input_dim=self.tar_vocab_size, output_dim=self.embedding_dim, \n",
    "                                        input_length=self.input_length, mask_zero=True, name=\"Decoder_Embedding\")\n",
    "    else:\n",
    "        self.decoder_embedding = Embedding(input_dim=self.tar_vocab_size, output_dim=self.embedding_dim, \n",
    "                                        input_length=self.input_length, weights = [embedding_matrix], trainable = False, mask_zero=True, name=\"Decoder_Embedding\")\n",
    "        \n",
    "    self.decoder_lstm = LSTM(self.att_units, return_state=True, return_sequences=True, name=\"Decoder_LSTM\")\n",
    "    self.attention = Attention(self.score_fun,self.att_units)\n",
    "    self.dense = Dense(self.tar_vocab_size, activation = 'softmax')\n",
    "\n",
    "  def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
    "    \n",
    "    dec_input_embedd = self.decoder_embedding(input_to_decoder) # BatchSizex1xEmbeddingUnits\n",
    "\n",
    "#     print('Dec:', dec_input_embedd.shape)\n",
    "    \n",
    "    context_vector, scores = self.attention(state_h,encoder_output) # BatchSizexEmbeddingUnits\n",
    "\n",
    "#     print('Con:', context_vector.shape)\n",
    "    \n",
    "    final_input = np.concatenate((dec_input_embedd,context_vector[:,np.newaxis,:]), axis=-1)\n",
    "    \n",
    "    decoder_output, decoder_state_h, decoder_state_c = self.decoder_lstm(final_input, initial_state = [state_h,state_c])\n",
    "    \n",
    "    final_output = self.dense(decoder_output) #BatchSizex1xVocabSize\n",
    "    \n",
    "    final_output = final_output[:,0,:] # BatchSizexVocabSize\n",
    "    \n",
    "    return final_output,decoder_state_h,decoder_state_c,scores,context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:26:32.618331Z",
     "iopub.status.busy": "2022-07-02T15:26:32.617826Z",
     "iopub.status.idle": "2022-07-02T15:26:32.638894Z",
     "shell.execute_reply": "2022-07-02T15:26:32.636501Z",
     "shell.execute_reply.started": "2022-07-02T15:26:32.618297Z"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1656166785053,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "NV-x31rj6Hc4"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units, flag = 0):\n",
    "      #Intializing necessary variables and creating an object from the class onestepdecoder\n",
    "        \n",
    "        super().__init__()\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.dec_embedding_dim = embedding_dim\n",
    "        self.dec_input_length = input_length\n",
    "        self.dec_lstm_size = dec_units\n",
    "        self.score_fun = score_fun\n",
    "        self.att_units = att_units\n",
    "        self.flag = flag\n",
    "        \n",
    "        self.onestepdecoder=OneStepDecoder(self.out_vocab_size, self.dec_embedding_dim, self.dec_input_length, self.dec_lstm_size ,self.score_fun ,self.att_units, self.flag)\n",
    "\n",
    "        \n",
    "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state, flag=0):\n",
    "        \n",
    "        all_outputs = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\n",
    "        \n",
    "        if flag == 0:\n",
    "            tmp = input_to_decoder.shape[1]\n",
    "        else:\n",
    "            tmp = 20\n",
    "            \n",
    "        for timestep in range(tmp): # for each timestep in decoder input\n",
    "            dec_input = input_to_decoder[:,timestep]\n",
    "            dec_input = dec_input[:,np.newaxis]\n",
    "            output,decoder_hidden_state,decoder_cell_state,attention_weights,context_vector=self.onestepdecoder(dec_input,encoder_output,decoder_hidden_state,decoder_cell_state)\n",
    "            all_outputs = all_outputs.write(timestep,output)\n",
    "\n",
    "        all_outputs = tf.transpose(all_outputs.stack(),[1,0,2])\n",
    "        return all_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fC1T1EOoMTqC"
   },
   "source": [
    "### Encoder Decoder Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:26:35.668788Z",
     "iopub.status.busy": "2022-07-02T15:26:35.668334Z",
     "iopub.status.idle": "2022-07-02T15:26:35.679151Z",
     "shell.execute_reply": "2022-07-02T15:26:35.677687Z",
     "shell.execute_reply.started": "2022-07-02T15:26:35.668754Z"
    },
    "executionInfo": {
     "elapsed": 423,
     "status": "ok",
     "timestamp": 1656166804296,
     "user": {
      "displayName": "Naveen Singh",
      "userId": "05732437636304892643"
     },
     "user_tz": -330
    },
    "id": "FfqBIe20MT3D"
   },
   "outputs": [],
   "source": [
    "class encoder_decoder(tf.keras.Model):\n",
    "  def __init__(self,batch_size,enc_input_length, dec_input_length,score_fun ,att_units,flag):\n",
    "    #Intializing objects from encoder decoder\n",
    "               \n",
    "    super().__init__()\n",
    "    self.batch_size = batch_size\n",
    "    self.enc_input_length = enc_input_length\n",
    "    self.dec_input_length = dec_input_length\n",
    "    self.score_fun = score_fun\n",
    "    self.att_units = att_units\n",
    "    self.flag = flag\n",
    "\n",
    "    self.encoder = Encoder(vocab_size_ita+1, 50, 64, self.enc_input_length)\n",
    "    self.decoder = Decoder(vocab_size_eng+1, 100, self.dec_input_length, 64, self.score_fun,self.att_units,self.flag)\n",
    "\n",
    "  \n",
    "  def call(self,data):\n",
    "\n",
    "    input_seq,output_seq = data[0], data[1]\n",
    "\n",
    "    initial_state=self.encoder.initialize_states(self.batch_size)\n",
    "\n",
    "    encoder_output, encoder_final_h, encoder_final_c = self.encoder(input_seq,initial_state)\n",
    "    decoder_output = self.decoder(output_seq,encoder_output, encoder_final_h, encoder_final_c,1)\n",
    "\n",
    "    return decoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dot ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T20:41:59.972416Z",
     "iopub.status.busy": "2022-06-25T20:41:59.971700Z",
     "iopub.status.idle": "2022-06-25T21:55:22.408972Z",
     "shell.execute_reply": "2022-06-25T21:55:22.407806Z",
     "shell.execute_reply.started": "2022-06-25T20:41:59.972379Z"
    },
    "id": "ePgwk4xmGaKF",
    "outputId": "df2c786c-01fc-43ab-f556-c43a125610f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "276/276 [==============================] - 175s 631ms/step - loss: 3.2646 - val_loss: 1.9699\n",
      "Epoch 2/25\n",
      "276/276 [==============================] - 172s 624ms/step - loss: 1.8274 - val_loss: 1.7165\n",
      "Epoch 3/25\n",
      "276/276 [==============================] - 176s 638ms/step - loss: 1.6357 - val_loss: 1.5525\n",
      "Epoch 4/25\n",
      "276/276 [==============================] - 173s 626ms/step - loss: 1.4770 - val_loss: 1.4035\n",
      "Epoch 5/25\n",
      "276/276 [==============================] - 176s 637ms/step - loss: 1.3436 - val_loss: 1.2861\n",
      "Epoch 6/25\n",
      "276/276 [==============================] - 188s 681ms/step - loss: 1.2300 - val_loss: 1.1812\n",
      "Epoch 7/25\n",
      "276/276 [==============================] - 179s 647ms/step - loss: 1.1287 - val_loss: 1.0913\n",
      "Epoch 8/25\n",
      "276/276 [==============================] - 175s 635ms/step - loss: 1.0465 - val_loss: 1.0224\n",
      "Epoch 9/25\n",
      "276/276 [==============================] - 174s 631ms/step - loss: 0.9798 - val_loss: 0.9646\n",
      "Epoch 10/25\n",
      "276/276 [==============================] - 172s 623ms/step - loss: 0.9229 - val_loss: 0.9157\n",
      "Epoch 11/25\n",
      "276/276 [==============================] - 173s 628ms/step - loss: 0.8723 - val_loss: 0.8712\n",
      "Epoch 12/25\n",
      "276/276 [==============================] - 174s 631ms/step - loss: 0.8274 - val_loss: 0.8325\n",
      "Epoch 13/25\n",
      "276/276 [==============================] - 174s 630ms/step - loss: 0.7867 - val_loss: 0.7970\n",
      "Epoch 14/25\n",
      "276/276 [==============================] - 174s 629ms/step - loss: 0.7495 - val_loss: 0.7656\n",
      "Epoch 15/25\n",
      "276/276 [==============================] - 173s 627ms/step - loss: 0.7158 - val_loss: 0.7355\n",
      "Epoch 16/25\n",
      "276/276 [==============================] - 173s 628ms/step - loss: 0.6843 - val_loss: 0.7093\n",
      "Epoch 17/25\n",
      "276/276 [==============================] - 174s 632ms/step - loss: 0.6557 - val_loss: 0.6856\n",
      "Epoch 18/25\n",
      "276/276 [==============================] - 174s 632ms/step - loss: 0.6296 - val_loss: 0.6633\n",
      "Epoch 19/25\n",
      "276/276 [==============================] - 187s 677ms/step - loss: 0.6056 - val_loss: 0.6435\n",
      "Epoch 20/25\n",
      "276/276 [==============================] - 174s 630ms/step - loss: 0.5834 - val_loss: 0.6254\n",
      "Epoch 21/25\n",
      "276/276 [==============================] - 173s 625ms/step - loss: 0.5626 - val_loss: 0.6074\n",
      "Epoch 22/25\n",
      "276/276 [==============================] - 173s 626ms/step - loss: 0.5433 - val_loss: 0.5921\n",
      "Epoch 23/25\n",
      "276/276 [==============================] - 172s 625ms/step - loss: 0.5255 - val_loss: 0.5776\n",
      "Epoch 24/25\n",
      "276/276 [==============================] - 172s 623ms/step - loss: 0.5091 - val_loss: 0.5651\n",
      "Epoch 25/25\n",
      "276/276 [==============================] - 173s 627ms/step - loss: 0.4937 - val_loss: 0.5525\n",
      "Model: \"encoder_decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_1 (Encoder)          multiple                  1360740   \n",
      "_________________________________________________________________\n",
      "decoder_3 (Decoder)          multiple                  2210884   \n",
      "=================================================================\n",
      "Total params: 3,571,624\n",
      "Trainable params: 2,267,224\n",
      "Non-trainable params: 1,304,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model  = encoder_decoder(batch_size = 1024,enc_input_length=20,dec_input_length=1,score_fun='dot',att_units=64,flag=1)\n",
    "opt = tf.keras.optimizers.Adam(0.001)\n",
    "model.compile(optimizer=opt,loss=tf.keras.losses.SparseCategoricalCrossentropy(), run_eagerly=True)\n",
    "\n",
    "train_steps=train.shape[0]//1024\n",
    "valid_steps=validation.shape[0]//1024\n",
    "\n",
    "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=25, validation_data=test_dataloader, validation_steps=valid_steps)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-25T21:55:22.411354Z",
     "iopub.status.busy": "2022-06-25T21:55:22.410903Z",
     "iopub.status.idle": "2022-06-25T21:55:22.460479Z",
     "shell.execute_reply": "2022-06-25T21:55:22.459619Z",
     "shell.execute_reply.started": "2022-06-25T21:55:22.411314Z"
    },
    "id": "H43M_UvhPTyk"
   },
   "outputs": [],
   "source": [
    "model.save_weights('W_Attention_25_dot.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T12:55:18.275230Z",
     "iopub.status.busy": "2022-06-27T12:55:18.274860Z",
     "iopub.status.idle": "2022-06-27T12:58:15.296766Z",
     "shell.execute_reply": "2022-06-27T12:58:15.294628Z",
     "shell.execute_reply.started": "2022-06-27T12:55:18.275197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_decoder_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_2 (Encoder)          multiple                  1360740   \n",
      "_________________________________________________________________\n",
      "decoder_4 (Decoder)          multiple                  2210884   \n",
      "=================================================================\n",
      "Total params: 3,571,624\n",
      "Trainable params: 2,267,224\n",
      "Non-trainable params: 1,304,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Loading Weights\n",
    "\n",
    "model  = encoder_decoder(batch_size = 1024,enc_input_length=20,dec_input_length=1,score_fun='dot',att_units=64,flag=1)\n",
    "opt = tf.keras.optimizers.Adam(0.001)\n",
    "model.compile(optimizer=opt,loss=tf.keras.losses.SparseCategoricalCrossentropy(), run_eagerly=True)\n",
    "\n",
    "train_steps=train.shape[0]//1024\n",
    "valid_steps=validation.shape[0]//1024\n",
    "\n",
    "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=1, validation_data=test_dataloader, validation_steps=valid_steps, verbose=0)\n",
    "model.load_weights('../input/tknizer/W_Attention_25_dot.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T12:58:42.749754Z",
     "iopub.status.busy": "2022-06-27T12:58:42.749362Z",
     "iopub.status.idle": "2022-06-27T12:58:42.762016Z",
     "shell.execute_reply": "2022-06-27T12:58:42.760552Z",
     "shell.execute_reply.started": "2022-06-27T12:58:42.749716Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(input_data):\n",
    "    \n",
    "    all_outputs = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\n",
    "    \n",
    "    initial_state = model.layers[0].initialize_states(input_data.shape[0]) \n",
    "\n",
    "    enc_output, state_h, state_c = model.layers[0](padded_test_seq,initial_state)\n",
    "\n",
    "    dec_input = np.array(tknizer_eng.texts_to_sequences(['<start>'])) # First word \n",
    "    dec_input = np.repeat(dec_input,1000) \n",
    "    dec_input = dec_input[:,np.newaxis] # 1000x1\n",
    "\n",
    "    osdec=OneStepDecoder(vocab_size_eng+1,100,1,64,'dot',64,1)\n",
    "    \n",
    "    output,decoder_hidden_state,decoder_cell_state,_,_ = osdec(dec_input,enc_output,state_h,state_c)\n",
    "    \n",
    "    all_outputs = all_outputs.write(0,output)\n",
    "    \n",
    "    for timestep in range(1,20): # for each timestep in decoder input\n",
    "        \n",
    "        max_prob_word_index = tf.math.argmax(output, axis=1)\n",
    "\n",
    "        tmp = [list(tknizer_eng.word_index.keys())[index] for index in max_prob_word_index]\n",
    "        \n",
    "        dec_input = np.array(tknizer_eng.texts_to_sequences(tmp))\n",
    "        \n",
    "        output,decoder_hidden_state,decoder_cell_state,_,_ = osdec(dec_input,enc_output,decoder_hidden_state,decoder_cell_state)\n",
    "    \n",
    "        all_outputs = all_outputs.write(timestep,output)\n",
    "        \n",
    "    all_outputs = all_outputs.write(timestep,output)\n",
    "\n",
    "    all_outputs = tf.transpose(all_outputs.stack(),[1,0,2])\n",
    "    \n",
    "    return all_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T12:58:42.765673Z",
     "iopub.status.busy": "2022-06-27T12:58:42.764931Z",
     "iopub.status.idle": "2022-06-27T12:58:43.236743Z",
     "shell.execute_reply": "2022-06-27T12:58:43.235667Z",
     "shell.execute_reply.started": "2022-06-27T12:58:42.765634Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "val_index = [index for index in validation.index.values]\n",
    "random_seq_index = random.sample(val_index,1000)\n",
    "\n",
    "sample_ita = data.loc[random_seq_index,'italian']\n",
    "actual_sample_eng = data.loc[random_seq_index,'english_out']\n",
    "\n",
    "test_seq = tknizer_ita.texts_to_sequences(sample_ita)\n",
    "padded_test_seq = pad_sequences(test_seq, 20, dtype='int32', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T12:58:43.238371Z",
     "iopub.status.busy": "2022-06-27T12:58:43.238016Z",
     "iopub.status.idle": "2022-06-27T12:58:54.368340Z",
     "shell.execute_reply": "2022-06-27T12:58:54.367348Z",
     "shell.execute_reply.started": "2022-06-27T12:58:43.238335Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = predict(padded_test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T12:58:54.370005Z",
     "iopub.status.busy": "2022-06-27T12:58:54.369663Z",
     "iopub.status.idle": "2022-06-27T12:58:54.376951Z",
     "shell.execute_reply": "2022-06-27T12:58:54.375796Z",
     "shell.execute_reply.started": "2022-06-27T12:58:54.369970Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = tf.math.argmax(preds, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T13:03:22.133604Z",
     "iopub.status.busy": "2022-06-27T13:03:22.132874Z",
     "iopub.status.idle": "2022-06-27T13:03:22.169643Z",
     "shell.execute_reply": "2022-06-27T13:03:22.168640Z",
     "shell.execute_reply.started": "2022-06-27T13:03:22.133547Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_eng = tknizer_eng.sequences_to_texts(preds.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-27T13:03:59.452969Z",
     "iopub.status.busy": "2022-06-27T13:03:59.452594Z",
     "iopub.status.idle": "2022-06-27T13:04:12.161035Z",
     "shell.execute_reply": "2022-06-27T13:04:12.160018Z",
     "shell.execute_reply.started": "2022-06-27T13:03:59.452936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Bleu: 0.794098876160373\n"
     ]
    }
   ],
   "source": [
    "pred_eng = pd.Series(pred_eng)\n",
    "print('Corpus Bleu:',nltk.translate.bleu_score.corpus_bleu(pred_eng,actual_sample_eng))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T15:26:50.447693Z",
     "iopub.status.busy": "2022-07-02T15:26:50.446694Z",
     "iopub.status.idle": "2022-07-02T18:25:00.770701Z",
     "shell.execute_reply": "2022-07-02T18:25:00.769731Z",
     "shell.execute_reply.started": "2022-07-02T15:26:50.447646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "276/276 [==============================] - 527s 2s/step - loss: 3.1932 - val_loss: 1.9377\n",
      "Epoch 2/25\n",
      "276/276 [==============================] - 538s 2s/step - loss: 1.8032 - val_loss: 1.6972\n",
      "Epoch 3/25\n",
      "276/276 [==============================] - 535s 2s/step - loss: 1.6204 - val_loss: 1.5373\n",
      "Epoch 4/25\n",
      "276/276 [==============================] - 442s 2s/step - loss: 1.4714 - val_loss: 1.3966\n",
      "Epoch 5/25\n",
      "276/276 [==============================] - 565s 2s/step - loss: 1.3356 - val_loss: 1.2769\n",
      "Epoch 6/25\n",
      "276/276 [==============================] - 474s 2s/step - loss: 1.2269 - val_loss: 1.1822\n",
      "Epoch 7/25\n",
      "276/276 [==============================] - 497s 2s/step - loss: 1.1387 - val_loss: 1.1041\n",
      "Epoch 8/25\n",
      "276/276 [==============================] - 489s 2s/step - loss: 1.0649 - val_loss: 1.0409\n",
      "Epoch 9/25\n",
      "276/276 [==============================] - 370s 1s/step - loss: 1.0036 - val_loss: 0.9868\n",
      "Epoch 10/25\n",
      "276/276 [==============================] - 407s 1s/step - loss: 0.9488 - val_loss: 0.9380\n",
      "Epoch 11/25\n",
      "276/276 [==============================] - 367s 1s/step - loss: 0.9002 - val_loss: 0.8961\n",
      "Epoch 12/25\n",
      "276/276 [==============================] - 344s 1s/step - loss: 0.8571 - val_loss: 0.8580\n",
      "Epoch 13/25\n",
      "276/276 [==============================] - 439s 2s/step - loss: 0.8184 - val_loss: 0.8239\n",
      "Epoch 14/25\n",
      "276/276 [==============================] - 440s 2s/step - loss: 0.7823 - val_loss: 0.7918\n",
      "Epoch 15/25\n",
      "276/276 [==============================] - 343s 1s/step - loss: 0.7491 - val_loss: 0.7637\n",
      "Epoch 16/25\n",
      "276/276 [==============================] - 437s 2s/step - loss: 0.7187 - val_loss: 0.7385\n",
      "Epoch 17/25\n",
      "276/276 [==============================] - 411s 1s/step - loss: 0.6906 - val_loss: 0.7126\n",
      "Epoch 18/25\n",
      "276/276 [==============================] - 335s 1s/step - loss: 0.6651 - val_loss: 0.6924\n",
      "Epoch 19/25\n",
      "276/276 [==============================] - 432s 2s/step - loss: 0.6415 - val_loss: 0.6717\n",
      "Epoch 20/25\n",
      "276/276 [==============================] - 383s 1s/step - loss: 0.6195 - val_loss: 0.6532\n",
      "Epoch 21/25\n",
      "276/276 [==============================] - 344s 1s/step - loss: 0.5989 - val_loss: 0.6355\n",
      "Epoch 22/25\n",
      "276/276 [==============================] - 345s 1s/step - loss: 0.5794 - val_loss: 0.6198\n",
      "Epoch 23/25\n",
      "276/276 [==============================] - 355s 1s/step - loss: 0.5608 - val_loss: 0.6031\n",
      "Epoch 24/25\n",
      "276/276 [==============================] - 365s 1s/step - loss: 0.5432 - val_loss: 0.5892\n",
      "Epoch 25/25\n",
      "276/276 [==============================] - 393s 1s/step - loss: 0.5265 - val_loss: 0.5756\n",
      "Model: \"encoder_decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_2 (Encoder)          multiple                  1360740   \n",
      "_________________________________________________________________\n",
      "decoder_3 (Decoder)          multiple                  2210884   \n",
      "=================================================================\n",
      "Total params: 3,571,624\n",
      "Trainable params: 2,267,224\n",
      "Non-trainable params: 1,304,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model  = encoder_decoder(batch_size = 1024,enc_input_length=20,dec_input_length=1,score_fun='general',att_units=64,flag=1)\n",
    "opt = tf.keras.optimizers.Adam(0.001)\n",
    "model.compile(optimizer=opt,loss=tf.keras.losses.SparseCategoricalCrossentropy(), run_eagerly=True)\n",
    "\n",
    "train_steps=train.shape[0]//1024\n",
    "valid_steps=validation.shape[0]//1024\n",
    "\n",
    "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=25, validation_data=test_dataloader, validation_steps=valid_steps)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T18:25:00.773392Z",
     "iopub.status.busy": "2022-07-02T18:25:00.772963Z",
     "iopub.status.idle": "2022-07-02T18:25:00.814937Z",
     "shell.execute_reply": "2022-07-02T18:25:00.813880Z",
     "shell.execute_reply.started": "2022-07-02T18:25:00.773351Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights('W_Attention_25_general.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T18:26:09.324266Z",
     "iopub.status.busy": "2022-07-02T18:26:09.323865Z",
     "iopub.status.idle": "2022-07-02T18:26:09.336396Z",
     "shell.execute_reply": "2022-07-02T18:26:09.335100Z",
     "shell.execute_reply.started": "2022-07-02T18:26:09.324233Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(input_data):\n",
    "    \n",
    "    all_outputs = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\n",
    "    \n",
    "    initial_state = model.layers[0].initialize_states(input_data.shape[0]) \n",
    "\n",
    "    enc_output, state_h, state_c = model.layers[0](padded_test_seq,initial_state)\n",
    "\n",
    "    dec_input = np.array(tknizer_eng.texts_to_sequences(['<start>'])) # First word \n",
    "    dec_input = np.repeat(dec_input,1000) \n",
    "    dec_input = dec_input[:,np.newaxis] # 1000x1\n",
    "\n",
    "    osdec=OneStepDecoder(vocab_size_eng+1,100,1,64,'dot',64,1)\n",
    "    \n",
    "    output,decoder_hidden_state,decoder_cell_state,_,_ = osdec(dec_input,enc_output,state_h,state_c)\n",
    "    \n",
    "    all_outputs = all_outputs.write(0,output)\n",
    "    \n",
    "    for timestep in range(1,20): # for each timestep in decoder input\n",
    "        \n",
    "        max_prob_word_index = tf.math.argmax(output, axis=1)\n",
    "\n",
    "        tmp = [list(tknizer_eng.word_index.keys())[index] for index in max_prob_word_index]\n",
    "        \n",
    "        dec_input = np.array(tknizer_eng.texts_to_sequences(tmp))\n",
    "        \n",
    "        output,decoder_hidden_state,decoder_cell_state,_,_ = osdec(dec_input,enc_output,decoder_hidden_state,decoder_cell_state)\n",
    "    \n",
    "        all_outputs = all_outputs.write(timestep,output)\n",
    "        \n",
    "    all_outputs = all_outputs.write(timestep,output)\n",
    "\n",
    "    all_outputs = tf.transpose(all_outputs.stack(),[1,0,2])\n",
    "    \n",
    "    return all_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T18:26:19.170241Z",
     "iopub.status.busy": "2022-07-02T18:26:19.169885Z",
     "iopub.status.idle": "2022-07-02T18:26:19.210195Z",
     "shell.execute_reply": "2022-07-02T18:26:19.209193Z",
     "shell.execute_reply.started": "2022-07-02T18:26:19.170211Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "val_index = [index for index in validation.index.values]\n",
    "random_seq_index = random.sample(val_index,1000)\n",
    "\n",
    "sample_ita = data.loc[random_seq_index,'italian']\n",
    "actual_sample_eng = data.loc[random_seq_index,'english_out']\n",
    "\n",
    "test_seq = tknizer_ita.texts_to_sequences(sample_ita)\n",
    "padded_test_seq = pad_sequences(test_seq, 20, dtype='int32', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T18:26:41.281048Z",
     "iopub.status.busy": "2022-07-02T18:26:41.280691Z",
     "iopub.status.idle": "2022-07-02T18:27:04.770927Z",
     "shell.execute_reply": "2022-07-02T18:27:04.769035Z",
     "shell.execute_reply.started": "2022-07-02T18:26:41.281020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Bleu: 0.7977816329796129\n"
     ]
    }
   ],
   "source": [
    "preds = predict(padded_test_seq)\n",
    "preds = tf.math.argmax(preds, axis=-1)\n",
    "\n",
    "pred_eng = tknizer_eng.sequences_to_texts(preds.numpy())\n",
    "pred_eng = pd.Series(pred_eng)\n",
    "\n",
    "print('Corpus Bleu:',nltk.translate.bleu_score.corpus_bleu(pred_eng,actual_sample_eng))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T11:29:18.767963Z",
     "iopub.status.busy": "2022-07-02T11:29:18.767602Z",
     "iopub.status.idle": "2022-07-02T13:38:38.083350Z",
     "shell.execute_reply": "2022-07-02T13:38:38.082409Z",
     "shell.execute_reply.started": "2022-07-02T11:29:18.767934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "276/276 [==============================] - 309s 1s/step - loss: 3.1855 - val_loss: 1.8946\n",
      "Epoch 2/25\n",
      "276/276 [==============================] - 299s 1s/step - loss: 1.7649 - val_loss: 1.6852\n",
      "Epoch 3/25\n",
      "276/276 [==============================] - 306s 1s/step - loss: 1.6089 - val_loss: 1.5431\n",
      "Epoch 4/25\n",
      "276/276 [==============================] - 303s 1s/step - loss: 1.4692 - val_loss: 1.4014\n",
      "Epoch 5/25\n",
      "276/276 [==============================] - 308s 1s/step - loss: 1.3282 - val_loss: 1.2760\n",
      "Epoch 6/25\n",
      "276/276 [==============================] - 308s 1s/step - loss: 1.2153 - val_loss: 1.1797\n",
      "Epoch 7/25\n",
      "276/276 [==============================] - 276s 999ms/step - loss: 1.1257 - val_loss: 1.1003\n",
      "Epoch 8/25\n",
      "276/276 [==============================] - 312s 1s/step - loss: 1.0519 - val_loss: 1.0365\n",
      "Epoch 9/25\n",
      "276/276 [==============================] - 310s 1s/step - loss: 0.9917 - val_loss: 0.9855\n",
      "Epoch 10/25\n",
      "276/276 [==============================] - 311s 1s/step - loss: 0.9400 - val_loss: 0.9405\n",
      "Epoch 11/25\n",
      "276/276 [==============================] - 307s 1s/step - loss: 0.8948 - val_loss: 0.9000\n",
      "Epoch 12/25\n",
      "276/276 [==============================] - 307s 1s/step - loss: 0.8543 - val_loss: 0.8649\n",
      "Epoch 13/25\n",
      "276/276 [==============================] - 310s 1s/step - loss: 0.8176 - val_loss: 0.8332\n",
      "Epoch 14/25\n",
      "276/276 [==============================] - 312s 1s/step - loss: 0.7835 - val_loss: 0.8019\n",
      "Epoch 15/25\n",
      "276/276 [==============================] - 310s 1s/step - loss: 0.7517 - val_loss: 0.7754\n",
      "Epoch 16/25\n",
      "276/276 [==============================] - 310s 1s/step - loss: 0.7220 - val_loss: 0.7491\n",
      "Epoch 17/25\n",
      "276/276 [==============================] - 312s 1s/step - loss: 0.6939 - val_loss: 0.7252\n",
      "Epoch 18/25\n",
      "276/276 [==============================] - 313s 1s/step - loss: 0.6675 - val_loss: 0.7021\n",
      "Epoch 19/25\n",
      "276/276 [==============================] - 309s 1s/step - loss: 0.6427 - val_loss: 0.6817\n",
      "Epoch 20/25\n",
      "276/276 [==============================] - 310s 1s/step - loss: 0.6191 - val_loss: 0.6609\n",
      "Epoch 21/25\n",
      "276/276 [==============================] - 309s 1s/step - loss: 0.5971 - val_loss: 0.6422\n",
      "Epoch 22/25\n",
      "276/276 [==============================] - 306s 1s/step - loss: 0.5763 - val_loss: 0.6253\n",
      "Epoch 23/25\n",
      "276/276 [==============================] - 308s 1s/step - loss: 0.5572 - val_loss: 0.6094\n",
      "Epoch 24/25\n",
      "276/276 [==============================] - 304s 1s/step - loss: 0.5394 - val_loss: 0.5947\n",
      "Epoch 25/25\n",
      "276/276 [==============================] - 304s 1s/step - loss: 0.5223 - val_loss: 0.5812\n",
      "Model: \"encoder_decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_1 (Encoder)          multiple                  1360740   \n",
      "_________________________________________________________________\n",
      "decoder_3 (Decoder)          multiple                  2210884   \n",
      "=================================================================\n",
      "Total params: 3,571,624\n",
      "Trainable params: 2,267,224\n",
      "Non-trainable params: 1,304,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model  = encoder_decoder(batch_size = 1024,enc_input_length=20,dec_input_length=1,score_fun='concat',att_units=64,flag=1)\n",
    "opt = tf.keras.optimizers.Adam(0.001)\n",
    "model.compile(optimizer=opt,loss=tf.keras.losses.SparseCategoricalCrossentropy(), run_eagerly=True)\n",
    "\n",
    "train_steps=train.shape[0]//1024\n",
    "valid_steps=validation.shape[0]//1024\n",
    "\n",
    "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=25, validation_data=test_dataloader, validation_steps=valid_steps)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T13:45:07.134932Z",
     "iopub.status.busy": "2022-07-02T13:45:07.133987Z",
     "iopub.status.idle": "2022-07-02T13:45:07.182293Z",
     "shell.execute_reply": "2022-07-02T13:45:07.181132Z",
     "shell.execute_reply.started": "2022-07-02T13:45:07.134895Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights('W_Attention_25_concat.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T13:45:57.443629Z",
     "iopub.status.busy": "2022-07-02T13:45:57.443024Z",
     "iopub.status.idle": "2022-07-02T13:45:57.458793Z",
     "shell.execute_reply": "2022-07-02T13:45:57.457568Z",
     "shell.execute_reply.started": "2022-07-02T13:45:57.443583Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(input_data):\n",
    "    \n",
    "    all_outputs = tf.TensorArray(tf.float32, size=0, dynamic_size=True)\n",
    "    \n",
    "    initial_state = model.layers[0].initialize_states(input_data.shape[0]) \n",
    "\n",
    "    enc_output, state_h, state_c = model.layers[0](padded_test_seq,initial_state)\n",
    "\n",
    "    dec_input = np.array(tknizer_eng.texts_to_sequences(['<start>'])) # First word \n",
    "    dec_input = np.repeat(dec_input,1000) \n",
    "    dec_input = dec_input[:,np.newaxis] # 1000x1\n",
    "\n",
    "    osdec=OneStepDecoder(vocab_size_eng+1,100,1,64,'dot',64,1)\n",
    "    \n",
    "    output,decoder_hidden_state,decoder_cell_state,_,_ = osdec(dec_input,enc_output,state_h,state_c)\n",
    "    \n",
    "    all_outputs = all_outputs.write(0,output)\n",
    "    \n",
    "    for timestep in range(1,20): # for each timestep in decoder input\n",
    "        \n",
    "        max_prob_word_index = tf.math.argmax(output, axis=1)\n",
    "\n",
    "        tmp = [list(tknizer_eng.word_index.keys())[index] for index in max_prob_word_index]\n",
    "        \n",
    "        dec_input = np.array(tknizer_eng.texts_to_sequences(tmp))\n",
    "        \n",
    "        output,decoder_hidden_state,decoder_cell_state,_,_ = osdec(dec_input,enc_output,decoder_hidden_state,decoder_cell_state)\n",
    "    \n",
    "        all_outputs = all_outputs.write(timestep,output)\n",
    "        \n",
    "    all_outputs = all_outputs.write(timestep,output)\n",
    "\n",
    "    all_outputs = tf.transpose(all_outputs.stack(),[1,0,2])\n",
    "    \n",
    "    return all_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T13:46:20.123078Z",
     "iopub.status.busy": "2022-07-02T13:46:20.122654Z",
     "iopub.status.idle": "2022-07-02T13:46:20.176778Z",
     "shell.execute_reply": "2022-07-02T13:46:20.175887Z",
     "shell.execute_reply.started": "2022-07-02T13:46:20.123039Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "val_index = [index for index in validation.index.values]\n",
    "random_seq_index = random.sample(val_index,1000)\n",
    "\n",
    "sample_ita = data.loc[random_seq_index,'italian']\n",
    "actual_sample_eng = data.loc[random_seq_index,'english_out']\n",
    "\n",
    "test_seq = tknizer_ita.texts_to_sequences(sample_ita)\n",
    "padded_test_seq = pad_sequences(test_seq, 20, dtype='int32', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-02T13:47:48.243848Z",
     "iopub.status.busy": "2022-07-02T13:47:48.243175Z",
     "iopub.status.idle": "2022-07-02T13:48:10.326553Z",
     "shell.execute_reply": "2022-07-02T13:48:10.325415Z",
     "shell.execute_reply.started": "2022-07-02T13:47:48.243814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Bleu: 0.7964345941820906\n"
     ]
    }
   ],
   "source": [
    "preds = predict(padded_test_seq)\n",
    "preds = tf.math.argmax(preds, axis=-1)\n",
    "\n",
    "pred_eng = tknizer_eng.sequences_to_texts(preds.numpy())\n",
    "pred_eng = pd.Series(pred_eng)\n",
    "\n",
    "print('Corpus Bleu:',nltk.translate.bleu_score.corpus_bleu(pred_eng,actual_sample_eng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+----------+------------+\n",
      "|               Description                | Function | Bleu Score |\n",
      "+------------------------------------------+----------+------------+\n",
      "| Simple Encoder Decoder without Attention |   N/A    |   0.7634   |\n",
      "|      Encoder Decoder with Attention      |   Dot    |   0.7940   |\n",
      "|      Encoder Decoder with Attention      | General  |   0.7977   |\n",
      "|      Encoder Decoder with Attention      |  Concat  |   0.7964   |\n",
      "+------------------------------------------+----------+------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "myTable = PrettyTable([\"Description\", \"Function\", \"Bleu Score\"])\n",
    "\n",
    "myTable.add_row([\"Simple Encoder Decoder without Attention\", \"N/A\", \"0.7634\"])\n",
    "myTable.add_row([\"Encoder Decoder with Attention\", \"Dot\", \"0.7940\"])\n",
    "myTable.add_row([\"Encoder Decoder with Attention\", \"General\", \"0.7977\"])\n",
    "myTable.add_row([\"Encoder Decoder with Attention\", \"Concat\", \"0.7964\"])\n",
    "  \n",
    "print(myTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
